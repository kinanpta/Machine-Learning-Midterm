{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## UTS Machine Learning - Regression\n",
        "\n",
        "**Name:** Agatha Kinanthi Pramdriswara Truly Amorta\n",
        "\n",
        "**Class:** TK-46-04\n",
        "\n",
        "**NIM:** 1103223212\n",
        "\n",
        "\n",
        "*- This notebook is part of the midterm assignment for the Machine Learning course.*  \n",
        "\n",
        "*- The objective is to build a regression pipeline to predict continuous values from given features.*\n"
      ],
      "metadata": {
        "id": "Opcah7ZVhK0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Imports**"
      ],
      "metadata": {
        "id": "D1ChM82HhdKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Core libraries for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Preprocessing and splitting\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "# Helper function for regression metrics\n",
        "def regression_report(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    print(f\"RMSE: {rmse:.4f}  MAE: {mae:.4f}  R2: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "J3q5YpTViz5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Mount Google Drive and Load Data**"
      ],
      "metadata": {
        "id": "77gMS3OJixsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15XEYmR3hBea"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "datasets = '/content/drive/MyDrive/Machine-Learning-Midterm-Datasets/'\n",
        "\n",
        "file_path = datasets + 'midterm-regresi-dataset.csv'\n",
        "file_size = os.path.getsize(file_path) / (1024*1024) #Megabyte\n",
        "print(f\"File size: {file_size:.2f} MB\")\n",
        "\n",
        "df = pd.read_csv(file_path, nrows=20000)\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"First 5 rows of the dataset: \\n\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "JQZfZiFek2dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "leClKde1k8sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "T6vjbX8ohNRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum().sort_values(ascending=False).head(10))"
      ],
      "metadata": {
        "id": "NirA0_g_hC7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlations\n",
        "correlation = df.corr()\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.heatmap(correlation.iloc[:20, :20], cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Correlation heatmap (first 20 features)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rSlPZQWsnc6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution\n",
        "sns.histplot(df[df.columns[0]], bins=30, kde=True)\n",
        "plt.title(f\"Distribution of target column: {df.columns[0]}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uO90uTLIn5PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Preprocessing**"
      ],
      "metadata": {
        "id": "VAQyVnm-oCtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target and features and handle missing values\n",
        "target_col = df.columns[0]\n",
        "y = df[target_col]\n",
        "X = df.drop(columns=[target_col])\n",
        "X = X.fillna(X.median()) #prevent errors\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features for Linear Regression\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "2uzAVTuroGyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data size\n",
        "print(\"Train shape:\", X_train.shape)"
      ],
      "metadata": {
        "id": "O09pFrhXip0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing data size\n",
        "print(\"Test shape:\", X_test.shape)"
      ],
      "metadata": {
        "id": "5rD0LSH1ivCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data standardization\n",
        "print(\"Scaled train sample:\\n\", X_train_s[:5])"
      ],
      "metadata": {
        "id": "3fj34aj3ixFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Baseline Models**"
      ],
      "metadata": {
        "id": "kSIyo1KNi6FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_s, y_train)\n",
        "pred_lr = lr.predict(X_test_s)\n",
        "\n",
        "print(\"===Linear Regression Performance===\")\n",
        "regression_report(y_test, pred_lr)"
      ],
      "metadata": {
        "id": "zCCe-aMZi9Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"===Random Forest Regressor Performance===\")\n",
        "regression_report(y_test, pred_rf)"
      ],
      "metadata": {
        "id": "jvwq28BVjB8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Basic Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "_CJd6Gaau00Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_grid_small = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [None, 10]\n",
        "}\n",
        "\n",
        "grid_small = GridSearchCV(\n",
        "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "    parameter_grid_small,\n",
        "    cv=2,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "\n",
        "grid_small.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters (small grid):\", grid_small.best_params_)\n",
        "\n",
        "best_rf_small = grid_small.best_estimator_\n",
        "pred_best_rf_small = best_rf_small.predict(X_test)\n",
        "\n",
        "print(\"Performance with small grid tuning:\")\n",
        "regression_report(y_test, pred_best_rf_small)"
      ],
      "metadata": {
        "id": "bAxsEGw0u_WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Interpretation of Results**\n",
        "\n",
        "- Linear Regression achieved RMSE of *9.3910*, MAE of *6.7686*, and R² of *0.2137*.\n",
        "- Random Forest archived RMSE of *9.0608*,  MAE of *6.6164*, and R² of *0.2680*. The baseline improved performance, showing lower error and higher R².\n",
        "- Hyperparameter tuning further optimized Random Forest, reducing RMSE and improving fit.\n"
      ],
      "metadata": {
        "id": "R3Xe8BQ2vKcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusion**\n",
        "\n",
        "Random Forest with tuned parameters is the best model for this dataset, capturing non-linear relationships better than Linear Regression."
      ],
      "metadata": {
        "id": "Qh754RKEwUc5"
      }
    }
  ]
}